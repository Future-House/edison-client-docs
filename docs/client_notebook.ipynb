{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edison platform client usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from edison_client import (\n",
    "    EdisonClient,\n",
    "    JobNames,\n",
    "    TaskRequest,\n",
    ")\n",
    "from edison_client.models import RuntimeConfig\n",
    "from ldp.agent import AgentConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client instantiation\n",
    "\n",
    "Here we instantiate an Edison client and authenticate our access to the platform.\n",
    "By default, the client will use the `EDISON_PLATFORM_API_KEY` environment variable to authenticate.\n",
    "The option `api_key` can be used to pass your API key.\n",
    "\n",
    "Please log in to the platform and go to your user settings to get your API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = EdisonClient(\n",
    "    api_key=os.getenv(\"EDISON_PLATFORM_API_KEY\", \"your-api-key\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a task to an available Edison job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the edison platform, we refer to the deployed combination of agent and environment as a `job`.\n",
    "Submitting a task to an edison job is done by calling the `create_task` method, which receives a `TaskRequest` object.\n",
    "\n",
    "For convenience, one can use the `run_tasks_until_done` method, which submits the task, waits for the task to be completed, and returns a list of `TaskResponse` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = TaskRequest(\n",
    "    name=JobNames.from_string(\"literature\"),\n",
    "    query=\"What is the molecule known to have the greatest solubility in water?\",\n",
    ")\n",
    "responses = client.run_tasks_until_done(task_data)\n",
    "task_response = responses[0]\n",
    "\n",
    "print(f\"Job status: {task_response.status}\")\n",
    "print(f\"Job answer: \\n{task_response.formatted_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also pass a `runtime_config` to the `run_tasks_until_done` method, which will be used to configure the agent on runtime.\n",
    "Here, we will define a agent configuration and include it in the `TaskRequest`. This agent is used to decide the next action to take.\n",
    "We will also use the `max_steps` parameter to limit the number of steps the agent will take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentConfig(\n",
    "    agent_type=\"SimpleAgent\",\n",
    "    agent_kwargs={\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"temperature\": 0.0,\n",
    "    },\n",
    ")\n",
    "task_data = TaskRequest(\n",
    "    name=JobNames.LITERATURE,\n",
    "    query=\"How many moons does earth have?\",\n",
    "    runtime_config=RuntimeConfig(agent=agent, max_steps=10),\n",
    ")\n",
    "responses = client.run_tasks_until_done(task_data)\n",
    "task_response = responses[0]\n",
    "\n",
    "print(f\"Job status: {task_response.status}\")\n",
    "print(f\"Job answer: \\n{task_response.formatted_answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue a job\n",
    "\n",
    "The platform allows to ask follow-up questions to the previous job.\n",
    "To accomplish that, we can use the `runtime_config` to pass the `task_id` of the previous task.\n",
    "\n",
    "Notice that `run_tasks_until_done` accepts both a `TaskRequest` object and a dictionary with keywords arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_data = TaskRequest(\n",
    "    name=JobNames.LITERATURE, query=\"How many species of birds are there?\"\n",
    ")\n",
    "\n",
    "responses = client.run_tasks_until_done(task_data)\n",
    "task_response = responses[0]\n",
    "\n",
    "print(f\"First job status: {task_response.status}\")\n",
    "print(f\"First job answer: \\n{task_response.formatted_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continued_job_data = {\n",
    "    \"name\": JobNames.LITERATURE,\n",
    "    \"query\": \"From the previous answer, specifically, how many species of crows are there?\",\n",
    "    \"runtime_config\": {\"continued_job_id\": task_response.task_id},\n",
    "}\n",
    "\n",
    "responses = client.run_tasks_until_done(continued_job_data)\n",
    "continued_task_response = responses[0]\n",
    "\n",
    "\n",
    "print(f\"Continued job status: {continued_task_response.status}\")\n",
    "print(f\"Continued job answer: \\n{continued_task_response.formatted_answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
